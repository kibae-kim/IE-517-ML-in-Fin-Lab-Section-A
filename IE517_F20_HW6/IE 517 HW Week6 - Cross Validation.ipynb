{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0569d5",
   "metadata": {},
   "source": [
    "# Part4: Github Link for IE517 at 2023, HW6\n",
    "https://github.com/kibae-kim/IE-517-ML-in-Fin-Lab-Section-A/tree/main/IE517_F20_HW6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ff7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1af08",
   "metadata": {},
   "source": [
    "# Part 1: Random test train splits\n",
    "- Load ccdefault dataset.\n",
    "- Split the dataset into training and testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f832dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ccdefault-2.csv')\n",
    "X, y = df.drop('DEFAULT', axis=1), df['DEFAULT']\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', \n",
    "                             random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf508d",
   "metadata": {},
   "source": [
    "- Train ML model on the training set.\n",
    "- In-sample accuracy score by predicting the target labels attached on the training set and comparing them with the true labels.\n",
    "- Out-of-sample accuracy score by predicting the output labels for the testing set and comparing them with the true output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5628d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 10\n",
    "in_sample_acc = np.zeros(num_sample)\n",
    "out_of_sample_acc = np.zeros(num_sample)\n",
    "\n",
    "for i in range(num_sample):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                       test_size=0.1,\n",
    "                                                       random_state=i,\n",
    "                                                       stratify=y)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    in_sample_acc[i] = accuracy_score(y_train, y_train_pred)\n",
    "    \n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    out_of_sample_acc[i] = accuracy_score(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7055bd73",
   "metadata": {},
   "source": [
    "- Calculate the mean and standard deviation of the in-sample accuracy scores\n",
    "- Calculate the mean and standard deviation of the out_of-sample accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2edbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_in_sample_acc = in_sample_acc.mean()\n",
    "std_in_sample_acc = in_sample_acc.std()\n",
    "mean_out_of_sample_acc = out_of_sample_acc.mean()\n",
    "std_out_of_sample_acc = out_of_sample_acc.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d47b1",
   "metadata": {},
   "source": [
    "- Report in a table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a44ca60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random state</th>\n",
       "      <th>in-sample-accuracy</th>\n",
       "      <th>out-of-sample-accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.739333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.726333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     random state  in-sample-accuracy  out-of-sample-accuracy\n",
       "0               0                 1.0                0.739333\n",
       "1               1                 1.0                0.729000\n",
       "2               2                 1.0                0.726333\n",
       "3               3                 1.0                0.732000\n",
       "4               4                 1.0                0.718333\n",
       "5               5                 1.0                0.736000\n",
       "6               6                 1.0                0.734333\n",
       "7               7                 1.0                0.733667\n",
       "8               8                 1.0                0.728667\n",
       "9               9                 1.0                0.728333\n",
       "mean                              1.0                0.730600\n",
       "std                               0.0                0.005575"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table = pd.DataFrame({'random state': range(10),\n",
    "                            'in-sample-accuracy': in_sample_acc,\n",
    "                            'out-of-sample-accuracy': out_of_sample_acc})\n",
    "\n",
    "report_table.loc['mean'] = ['', mean_in_sample_acc, mean_out_of_sample_acc]\n",
    "report_table.loc['std'] = ['', std_in_sample_acc, std_out_of_sample_acc]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba61113",
   "metadata": {},
   "source": [
    "# Part 2: Cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6da74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4bb1a",
   "metadata": {},
   "source": [
    "- Split entire dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eeb2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.1,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee1973",
   "metadata": {},
   "source": [
    "- ML model selection as DecisionTreeClassifier\n",
    "- Record 10-fold cross-validation\n",
    "- Calculate mean, standard deviation of cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb907aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "mean_cv_scores = cv_scores.mean()\n",
    "std_cv_scores = cv_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a406df2c",
   "metadata": {},
   "source": [
    "- Report in a table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056ed8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.720741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.713704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.727778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.723704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.734815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.725926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.724037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cv_scores\n",
       "0      0.734444\n",
       "1      0.720370\n",
       "2      0.720741\n",
       "3      0.716667\n",
       "4      0.722222\n",
       "5      0.713704\n",
       "6      0.727778\n",
       "7      0.723704\n",
       "8      0.734815\n",
       "9      0.725926\n",
       "mean   0.724037\n",
       "std    0.006564"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table = pd.DataFrame({'cv_scores': cv_scores})\n",
    "report_table.loc['mean'] = [mean_cv_scores]\n",
    "report_table.loc['std'] = [std_cv_scores]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae92589",
   "metadata": {},
   "source": [
    "# Part 3: Conclusions\n",
    "- Both ways of measuring accuracy are efficient to evaluate performance of DecisionTreeClassifier. However, provided information are slightly different from each other. \n",
    "- In Part 1, usual holdout method show how DecisionTreeClassifier's performs on specific subsets of data. But, it may be sensitively affected by the randomness of the splits.\n",
    "- In Part 2, cross-validation is more stable in evaluating performance of DecisionTreeClassifier because it randomly split training set into 9 training folds and 1 test folds without replacement.\n",
    "- If we have enough computiational resources, Cross-validation is more reliable method to evaluate data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67fed72",
   "metadata": {},
   "source": [
    "# Academic Integrity Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60734e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Kibae Kim\n",
      "My NetID is: kibaek2\n",
      "I hereby certify that I have read the University policy on Academic Integrity and that I am not in violation.\n"
     ]
    }
   ],
   "source": [
    "print(\"My name is Kibae Kim\")\n",
    "print(\"My NetID is: kibaek2\")\n",
    "print(\"I hereby certify that I have read the University policy on Academic Integrity and that I am not in violation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
